{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39890f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from  matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import copy as cp\n",
    "import os \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83b997a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB_ZB(sets):\n",
    "    b,g,r=cv.split(sets)\n",
    "    m=cv.merge((r,g,b))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a253d347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['djc', 'ng', 'ok']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb_lj=r'D:\\Documents\\WeChat Files\\wxid_txb2wzx5w29u22\\FileStorage\\File\\2022-12\\Camera1\\wi'\n",
    "lb_mc=os.listdir(lb_lj)\n",
    "lb_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f17c0221",
   "metadata": {},
   "outputs": [],
   "source": [
    "lables=[]\n",
    "data_list=[]\n",
    "dst_size =(128,128)\n",
    "\n",
    "for j in range(len(lb_mc)):\n",
    "    lb_lj_ng='%s\\%s'%(lb_lj,lb_mc[j])  \n",
    "    lb_lj_ng_list=os.listdir(lb_lj_ng)\n",
    "    for i in range(len(lb_lj_ng_list)):\n",
    "        lb_lj_ng_list[i]='%s\\%s'%(lb_lj_ng,lb_lj_ng_list[i])  \n",
    "        dissa=RGB_ZB(cv.imread(lb_lj_ng_list[i],cv.IMREAD_COLOR))\n",
    "        img_resize= cv.resize(dissa,dst_size,interpolation=cv.INTER_AREA)\n",
    "        img_ywjz=img_resize.reshape((1,dst_size[1]*dst_size[0]*3))\n",
    "#         data_list.append(img_ywjz[np.newaxis, :])\n",
    "        data_list.append(img_ywjz)\n",
    "#         lables.append(lb_mc[j])\n",
    "        lables.append(j)\n",
    "    data=np.concatenate(data_list,axis=0)\n",
    "#     data=np.hstack([data,np.ones((data.shape[0],1))])\n",
    "lables=np.array(lables).reshape((len(lables),1))\n",
    "data=np.hstack([data,lables])\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f239f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, ..., 2, 1, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:,-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2868c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets perform stochastic gradient descent to learn the seperating hyperplane between both classes\n",
    "\n",
    "\n",
    "def svm_sgd_plot(X, Y):\n",
    "    #Initialize our SVMs weight vector with zeros (3 values)\n",
    "    w = np.zeros(len(X[0]))\n",
    "    #The learning rate\n",
    "    eta = 1\n",
    "    #how many iterations to train for\n",
    "    epochs = 100000\n",
    "    #store misclassifications so we can plot how they change over time\n",
    "    errors = []\n",
    "\n",
    "    #training part, gradient descent part\n",
    "    for epoch in range(1,epochs):\n",
    "        error = 0\n",
    "        for i, x in enumerate(X):\n",
    "        # 算法核心，使用梯度下降更新参数，\n",
    "        # 其中的条件判断和梯度更新公式是上图数学推导的最后两步。\n",
    "            #当分类错误的时候\n",
    "            if (Y[i]*np.dot(X[i], w)) < 1:\n",
    "                #分类错误时，梯度下降更新w参数（这里参数更新加上了w的L2正则化防止过拟合）\n",
    "                # 并且随着epoch的增加正则化效果越来越弱，1/epoch的作用\n",
    "                w = w - eta * ( -(X[i] * Y[i]) - (2 *(1/epoch)* w) )\n",
    "                error = 1\n",
    "            else:\n",
    "                # 正确分类时，更新w参数\n",
    "                w = w - eta * (2 *(1/epoch)* w)\n",
    "        errors.append(error)\n",
    "        \n",
    "    \n",
    "    #lets plot the rate of classification errors during training for our SVM\n",
    "    plt.plot(errors, '|')\n",
    "    plt.ylim(0.5,1.5)\n",
    "    plt.axes().set_yticklabels([])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Misclassified')\n",
    "    plt.show()\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ca7f1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51f5c095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12527.829399838527"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.pow(1.1,99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1894224e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
