{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96761a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954826e7c0384df682aa4e7cdfe1518d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9608030c6a9448ffb6b236d1bce5e0f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00d350743104b3db7ccacecedeb74c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bac70bb662540dfb63bfc66380bb06c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./mnist\\MNIST\\raw\n",
      "\n",
      "now epoch :   0    |  loss : 2.3075       |   accuracy :    0.1435\n",
      "now epoch :   0    |  loss : 0.4418       |   accuracy :    0.818\n",
      "now epoch :   0    |  loss : 0.3806       |   accuracy :    0.906\n",
      "now epoch :   0    |  loss : 0.1455       |   accuracy :    0.9195\n",
      "now epoch :   0    |  loss : 0.1317       |   accuracy :    0.9225\n",
      "now epoch :   0    |  loss : 0.0974       |   accuracy :    0.935\n",
      "now epoch :   0    |  loss : 0.1951       |   accuracy :    0.9485\n",
      "now epoch :   0    |  loss : 0.1620       |   accuracy :    0.952\n",
      "now epoch :   0    |  loss : 0.0908       |   accuracy :    0.96\n",
      "now epoch :   0    |  loss : 0.1475       |   accuracy :    0.9625\n",
      "now epoch :   0    |  loss : 0.0582       |   accuracy :    0.961\n",
      "now epoch :   0    |  loss : 0.0951       |   accuracy :    0.971\n",
      "now epoch :   0    |  loss : 0.1425       |   accuracy :    0.9715\n",
      "now epoch :   0    |  loss : 0.1214       |   accuracy :    0.97\n",
      "now epoch :   0    |  loss : 0.1280       |   accuracy :    0.9745\n",
      "now epoch :   0    |  loss : 0.0990       |   accuracy :    0.969\n",
      "now epoch :   0    |  loss : 0.1183       |   accuracy :    0.968\n",
      "now epoch :   0    |  loss : 0.0404       |   accuracy :    0.972\n",
      "now epoch :   0    |  loss : 0.1090       |   accuracy :    0.9665\n",
      "now epoch :   0    |  loss : 0.0482       |   accuracy :    0.976\n",
      "now epoch :   0    |  loss : 0.0226       |   accuracy :    0.9745\n",
      "now epoch :   0    |  loss : 0.1373       |   accuracy :    0.973\n",
      "now epoch :   0    |  loss : 0.0520       |   accuracy :    0.98\n",
      "now epoch :   0    |  loss : 0.0272       |   accuracy :    0.9745\n",
      "[7, 2, 1, 0, 4, 1, 4, 9, 5, 9] predecton Result\n",
      "[7, 2, 1, 0, 4, 1, 4, 9, 5, 9] Real Result\n"
     ]
    }
   ],
   "source": [
    "# @Time : 2020/6/6 13:23 \n",
    "# @Author : kingback\n",
    "# @File : cnn_test.py \n",
    "# @Software: PyCharm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Hyper prameters\n",
    "EPOCH=1\n",
    "BATCH_SIZE=50\n",
    "LR=0.001\n",
    "DOWNLOAD_MNIST=False\n",
    "\n",
    "train_data=torchvision.datasets.MNIST(\n",
    "    root='./mnist',\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),    #将下载的文件转换成pytorch认识的tensor类型，且将图片的数值大小从（0-255）归一化到（0-1）\n",
    "    download=True\n",
    ")\n",
    "\n",
    "#画一个图片显示出来\n",
    "# print(train_data.data.size())\n",
    "# print(train_data.targets.size())\n",
    "# plt.imshow(train_data.data[0].numpy(),cmap='gray')\n",
    "# plt.title('%i'%train_data.targets[0])\n",
    "# plt.show()    \n",
    "\n",
    "\n",
    "train_loader=Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_data=torchvision.datasets.MNIST(\n",
    "    root='./mnist',\n",
    "    train=False,\n",
    ")\n",
    "with torch.no_grad():\n",
    "    test_x=Variable(torch.unsqueeze(test_data.data, dim=1)).type(torch.FloatTensor)[:2000]/255   #只取前两千个数据吧，差不多已经够用了，然后将其归一化。\n",
    "    test_y=test_data.targets[:2000]\n",
    "    \n",
    "\n",
    "'''开始建立CNN网络'''\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        '''\n",
    "        一般来说，卷积网络包括以下内容：\n",
    "        1.卷积层\n",
    "        2.神经网络\n",
    "        3.池化层\n",
    "        '''\n",
    "        self.conv1=nn.Sequential(\n",
    "            nn.Conv2d(              #--> (1,28,28)\n",
    "                in_channels=1,      #传入的图片是几层的，灰色为1层，RGB为三层\n",
    "                out_channels=16,    #输出的图片是几层\n",
    "                kernel_size=5,      #代表扫描的区域点为5*5\n",
    "                stride=1,           #就是每隔多少步跳一下\n",
    "                padding=2,          #边框补全，其计算公式=（kernel_size-1）/2=(5-1)/2=2\n",
    "            ),    # 2d代表二维卷积           --> (16,28,28)\n",
    "            nn.ReLU(),              #非线性激活层\n",
    "            nn.MaxPool2d(kernel_size=2),    #设定这里的扫描区域为2*2，且取出该2*2中的最大值          --> (16,14,14)\n",
    "        )\n",
    "\n",
    "        self.conv2=nn.Sequential(\n",
    "            nn.Conv2d(              #       --> (16,14,14)\n",
    "                in_channels=16,     #这里的输入是上层的输出为16层\n",
    "                out_channels=32,    #在这里我们需要将其输出为32层\n",
    "                kernel_size=5,      #代表扫描的区域点为5*5\n",
    "                stride=1,           #就是每隔多少步跳一下\n",
    "                padding=2,          #边框补全，其计算公式=（kernel_size-1）/2=(5-1)/2=\n",
    "            ),                      #   --> (32,14,14)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),    #设定这里的扫描区域为2*2，且取出该2*2中的最大值     --> (32,7,7)，这里是三维数据\n",
    "        )\n",
    "\n",
    "        self.out=nn.Linear(32*7*7,10)       #注意一下这里的数据是二维的数据\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.conv2(x)     #（batch,32,7,7）\n",
    "        #然后接下来进行一下扩展展平的操作，将三维数据转为二维的数据\n",
    "        x=x.view(x.size(0),-1)    #(batch ,32 * 7 * 7)\n",
    "        output=self.out(x)\n",
    "        return output\n",
    "         \n",
    "cnn=CNN()\n",
    "# print(cnn)\n",
    "\n",
    "# 添加优化方法\n",
    "optimizer=torch.optim.Adam(cnn.parameters(),lr=LR)\n",
    "# 指定损失函数使用交叉信息熵\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "\n",
    "'''\n",
    "开始训练我们的模型哦\n",
    "'''\n",
    "step=0\n",
    "for epoch in range(EPOCH):\n",
    "    #加载训练数据\n",
    "    for step,data in enumerate(train_loader):\n",
    "        x,y=data\n",
    "        #分别得到训练数据的x和y的取值\n",
    "        b_x=Variable(x)\n",
    "        b_y=Variable(y)\n",
    "\n",
    "        output=cnn(b_x)         #调用模型预测\n",
    "        loss=loss_fn(output,b_y)#计算损失值\n",
    "        optimizer.zero_grad()   #每一次循环之前，将梯度清零\n",
    "        loss.backward()         #反向传播\n",
    "        optimizer.step()        #梯度下降\n",
    "\n",
    "        #每执行50次，输出一下当前epoch、loss、accuracy\n",
    "        if (step%50==0):\n",
    "            #计算一下模型预测正确率\n",
    "            test_output=cnn(test_x)\n",
    "            y_pred=torch.max(test_output,1)[1].data.squeeze()\n",
    "            accuracy=sum(y_pred==test_y).item()/test_y.size(0)\n",
    "\n",
    "            print('now epoch :  ', epoch, '   |  loss : %.4f ' % loss.item(), '     |   accuracy :   ' , accuracy)\n",
    "'''\n",
    "打印十个测试集的结果\n",
    "'''\n",
    "\n",
    "test_output=cnn(test_x[:10])\n",
    "y_pred=torch.max(test_output,1)[1].data.squeeze()       #选取最大可能的数值所在的位置\n",
    "print(y_pred.tolist(),'predecton Result')\n",
    "print(test_y[:10].tolist(),'Real Result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46a6ccf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d1f2a4d19f9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#画一个图片显示出来\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%i'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#画一个图片显示出来\n",
    "print(train_data.data.size())\n",
    "print(train_data.targets.size())\n",
    "plt.imshow(train_data.data[0].numpy(),cmap='gray')\n",
    "plt.title('%i'%train_data.targets[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b8ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
