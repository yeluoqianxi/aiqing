{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce9a2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = [['是', '单身', 125, '否'],\n",
    "           ['否', '已婚', 100, '否'],\n",
    "           ['否', '单身', 70, '否'],\n",
    "           ['是', '已婚', 120, '否'],\n",
    "           ['否', '离异', 95, '是'],\n",
    "           ['否', '已婚', 60, '否'],\n",
    "           ['是', '离异', 220, '否'],\n",
    "           ['否', '单身', 85, '是'],\n",
    "           ['否', '已婚', 75, '否'],\n",
    "           ['否', '单身', 90, '是']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdd4afd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dataSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d7e4f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "否\n",
      "否\n",
      "否\n",
      "否\n",
      "是\n",
      "否\n",
      "否\n",
      "是\n",
      "否\n",
      "是\n"
     ]
    }
   ],
   "source": [
    "numEntries = len(dataSet)     #数据集的记录条数\n",
    "labelCounts ={}               #生成一个空的字典\n",
    "for featVec in dataSet:       \n",
    "    currentLabel = featVec[-1]\n",
    "    print(currentLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39c4d5ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-92ccb011ce3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabelCounts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabelCounts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnumEntries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mshannonEnt\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshannonEnt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'log' is not defined"
     ]
    }
   ],
   "source": [
    "numEntries = len(dataSet)     #数据集的记录条数\n",
    "labelCounts ={}               #生成一个空的字典\n",
    "for featVec in dataSet:       \n",
    "    currentLabel = featVec[-1]  #读取需要更新的类的具体明细\n",
    "    if currentLabel not in labelCounts.keys():\n",
    "        labelCounts[currentLabel] =0\n",
    "    labelCounts[currentLabel] += 1\n",
    "shannonEnt = 0.0\n",
    "for label in labelCounts.keys():\n",
    "    prob = float(labelCounts[label])/numEntries\n",
    "    shannonEnt -= prob*log(prob,2)\n",
    "    print(shannonEnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44beabba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Graph_Matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c4162c720406>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m           \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# g\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m           [0, 0, 0, 0, 0, 1, 1, 0]]  # h\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mGraph_Matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Graph_Matrix' is not defined"
     ]
    }
   ],
   "source": [
    "import \n",
    "\n",
    "nodes = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "matrix = [[0, 1, 1, 1, 1, 1, 0, 0],  # a\n",
    "          [0, 0, 1, 0, 1, 0, 0, 0],  # b\n",
    "          [0, 0, 0, 1, 0, 0, 0, 0],  # c\n",
    "          [0, 0, 0, 0, 1, 0, 0, 0],  # d\n",
    "          [0, 0, 0, 0, 0, 1, 0, 0],  # e\n",
    "          [0, 0, 1, 0, 0, 0, 1, 1],  # f\n",
    "          [0, 0, 0, 0, 0, 1, 0, 1],  # g\n",
    "          [0, 0, 0, 0, 0, 1, 1, 0]]  # h\n",
    "Graph_Matrix(nodes,matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7265917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.create_undirected_matrix(my_graph)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d345cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73bb7c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.ones((16, 16))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50891076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 3\n"
     ]
    }
   ],
   "source": [
    "matrix =[[1,2], [3,4]]\n",
    "for i,element in enumerate(matrix):\n",
    "     print(i, element[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67c3679e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "1\n",
      "16\n",
      "2\n",
      "16\n",
      "3\n",
      "16\n",
      "4\n",
      "16\n",
      "5\n",
      "16\n",
      "6\n",
      "16\n",
      "7\n",
      "16\n",
      "8\n",
      "16\n",
      "9\n",
      "16\n",
      "10\n",
      "16\n",
      "11\n",
      "16\n",
      "12\n",
      "16\n",
      "13\n",
      "16\n",
      "14\n",
      "16\n",
      "15\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i ,element in enumerate(a):\n",
    "    count=len(element)\n",
    "#     print(len(element))\n",
    "    asd={}\n",
    "    for j in range(count):\n",
    "        if element[j]>0:\n",
    "            x=j+1\n",
    "            y=element[j]\n",
    "            asd.update( {'Germany' : 49} )\n",
    "       \n",
    "    print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605a0af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import numpy as np\n",
    "\n",
    "#数据获取及预处理\n",
    "class MNISTLoader():\n",
    "    def __init__(self):\n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        (self.train_data, self.train_label),(self.test_data,self.test_label)=mnist.load_data()\n",
    "        #给数据增加一个通道，也就是一个维度，图片色彩维度\n",
    "        self.train_data = np.expand_dims(self.train_data.astype(np.float32)/255.0,axis=-1)\n",
    "        self.test_data = np.expand_dims(self.test_data.astype(np.float32)/255.0,axis=-1)\n",
    "        self.train_label = self.train_label.astype(np.float32)\n",
    "        self.test_label = self.test_label.astype(np.float32)\n",
    "        self.num_train_data, self.num_test_data = self.train_data.shape[0],self.test_data.shape[0]\n",
    "\n",
    "    def get_batch(self, batch_size):\n",
    "        index = np.random.randint(0, np.shape(self.train_data)[0],batch_size)\n",
    "        return self.train_data[index, :], self.train_label[index]\n",
    "\n",
    "#模型的构建   tf.keras.Model 和 tf.keras.layers 这里使用的是函数式编程\n",
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        #关联父类构造函数\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            filters=32,            #卷积层神经元个数\n",
    "            kernel_size=[5, 5],    #感受野大小\n",
    "            padding='same',        #是否进行边界填充，Same填充后输入输出维度一样\n",
    "            activation=tf.nn.relu  #激活函数\n",
    "        )\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D(pool_size=[2,2], strides=2)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=[5,5],\n",
    "            padding='same',\n",
    "            activation=tf.nn.relu\n",
    "        )\n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D(pool_size=[2, 2], strides=2)\n",
    "        self.flatten = tf.keras.layers.Reshape(target_shape=(7*7*64,))\n",
    "        self.dense1 = tf.keras.layers.Dense(units=1024, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=10)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        output = tf.nn.softmax(x)\n",
    "        return output\n",
    "#模型训练\n",
    "\n",
    "#定义一些超参数\n",
    "num_epochs = 10           #迭代次数\n",
    "batch_size = 50          #每批数据的大小\n",
    "learning_rate = 0.001    #学习率\n",
    "\n",
    "model = CNN()\n",
    "data_loader = MNISTLoader()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "num_batches = int(data_loader.num_train_data//batch_size*num_epochs)\n",
    "for batch_index in range(num_batches):\n",
    "    X, y = data_loader.get_batch(batch_size)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X)\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y,y_pred=y_pred)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "\n",
    "    #print(\"epoch %d: loss %f\" % (, loss.numpy()))\n",
    "    grads = tape.gradient(loss, model.variables)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "\n",
    "\n",
    "#模型评估\n",
    "sparse_categorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "num_batches = int(data_loader.num_test_data // batch_size)\n",
    "for batch_index in range(num_batches):\n",
    "    start_index, end_index = batch_index * batch_size, (batch_index + 1) * batch_size\n",
    "    y_pred = model.predict(data_loader.test_data[start_index: end_index])\n",
    "    sparse_categorical_accuracy.update_state(y_true=data_loader.test_label[start_index: end_index], y_pred=y_pred)\n",
    "print(\"test accuracy: %f\" % sparse_categorical_accuracy.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65eb31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
